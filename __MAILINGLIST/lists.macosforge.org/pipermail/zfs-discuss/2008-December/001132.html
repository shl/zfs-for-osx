<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [zfs-discuss] Possible Mirror a stripe (or raidz) pool? Or	Replicate to separate pool?
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:zfs-discuss%40lists.macosforge.org?Subject=Re%3A%20%5Bzfs-discuss%5D%20Possible%20Mirror%20a%20stripe%20%28or%20raidz%29%20pool%3F%20Or%0A%09Replicate%20to%20separate%20pool%3F&In-Reply-To=%3Cf8207d190812021047j337d61e5ka039585e5575ce42%40mail.gmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="001128.html">
   <LINK REL="Next"  HREF="001133.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[zfs-discuss] Possible Mirror a stripe (or raidz) pool? Or	Replicate to separate pool?</H1>
    <B>Aaron Berland</B> 
    <A HREF="mailto:zfs-discuss%40lists.macosforge.org?Subject=Re%3A%20%5Bzfs-discuss%5D%20Possible%20Mirror%20a%20stripe%20%28or%20raidz%29%20pool%3F%20Or%0A%09Replicate%20to%20separate%20pool%3F&In-Reply-To=%3Cf8207d190812021047j337d61e5ka039585e5575ce42%40mail.gmail.com%3E"
       TITLE="[zfs-discuss] Possible Mirror a stripe (or raidz) pool? Or	Replicate to separate pool?">fruitboi at gmail.com
       </A><BR>
    <I>Tue Dec  2 10:47:10 PST 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="001128.html">[zfs-discuss] Possible Mirror a stripe (or raidz) pool? Or	Replicate to separate pool?
</A></li>
        <LI>Next message: <A HREF="001133.html">[zfs-discuss] zfs and kernel memory?
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1132">[ date ]</a>
              <a href="thread.html#1132">[ thread ]</a>
              <a href="subject.html#1132">[ subject ]</a>
              <a href="author.html#1132">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Rich, Thank you so much for your reply!

I have been reading more into snapshots and will start to experiment (with
redundant data of course).

I'm going to set my 1TB drive it as a separate pool and figure out
snapshots.  I sure can't wait for new bits that are much closer to release
quality and functionality!  Thanks for everyone contributing to the
project!

Just for fun I'm going to install NexentaSTOR on my box and see what iSCSI
performance looks like on bare metal to my MBP.  Never hurts to have the
experience, right?

Thank you again!  I really appreciate your response, Rich.

Regards,
Aaron

On Tue, Dec 2, 2008 at 12:38 AM, Rich McClellan &lt;<A HREF="http://lists.macosforge.org/mailman/listinfo.cgi/zfs-discuss">richmc at gmail.com</A>&gt; wrote:

&gt;<i> On Mon, Dec 1, 2008 at 6:39 PM, Aaron Berland &lt;<A HREF="http://lists.macosforge.org/mailman/listinfo.cgi/zfs-discuss">fruitboi at gmail.com</A>&gt; wrote:
</I>&gt;<i> &gt; Is it possible to mirror a raidz or striped pool to a single device
</I>&gt;<i> &gt; effectively?
</I>&gt;<i>
</I>&gt;<i> No.  It's antithetical to the ZFS Way.  However, it can be forced with
</I>&gt;<i> the -f option.
</I>&gt;<i>
</I>&gt;<i> &gt; Is it better to replicate the original pool to a separate pool?  If so,
</I>&gt;<i> what
</I>&gt;<i> &gt; is the best way?  Snapshots and send/recv are still a little taboo for me
</I>&gt;<i> &gt; :-/
</I>&gt;<i>
</I>&gt;<i> If you're not ready for snapshots, get ready.  If it's impossible for
</I>&gt;<i> you to embrace them, use rsync.
</I>&gt;<i>
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; I would like to pickup a 1TB drive and increase my storage space and
</I>&gt;<i> &gt; redundancy by:
</I>&gt;<i> &gt; a. converting the raidz pool to a striped pool and mirror it onto the 1TB
</I>&gt;<i> &gt; drive (3x320 stripe + 1TB mirror of the stripe)
</I>&gt;<i>
</I>&gt;<i> Do you mean create a mirror vdev out of the 3x320 + 1TB drives?  See
</I>&gt;<i> comment above about -f. Again, it goes against the grain, but you can
</I>&gt;<i> force it.  Split the 1TB drive in to 3 partitions equal in size to
</I>&gt;<i> your 320 GB drives and create a mirror vdev out of the six &quot;disks&quot;.
</I>&gt;<i>
</I>&gt;<i> &gt; b. Keep the raidz pool as is and do replication of that pool onto the 1TB
</I>&gt;<i> &gt; drive as a separate 1 drive zfs &quot;pool&quot;
</I>&gt;<i>
</I>&gt;<i> Sure, this works. Use rsync or better yet snapshot.
</I>&gt;<i>
</I>&gt;<i> &gt; c. Go crazy and use NexentaSTOR on a VM to export the storage with iSCSI
</I>&gt;<i> and
</I>&gt;<i> &gt; have a real HFS+ volume on the Mac (I actually did this, but performance
</I>&gt;<i> is
</I>&gt;<i> &gt; abysmal.  Average of 5MB/s writes and peaks at about 20MB/s.  Reads are
</I>&gt;<i> no
</I>&gt;<i> &gt; faster.)
</I>&gt;<i>
</I>&gt;<i> I do something similar to this using Linux as the iSCSI target/server
</I>&gt;<i> with the GlobalSAN iSCSI Mac OS X initiator.  Group together the
</I>&gt;<i> various LUNs and create a single target out of it.  Let ZFS on the Mac
</I>&gt;<i> create the vdevs.  It works for me.  I see my Gb network saturate when
</I>&gt;<i> transferring large files.  No stability issues.  I ended up using real
</I>&gt;<i> hardware because the VM approach for Solaris 10 and Linux was slow, as
</I>&gt;<i> you observed.  (I also tried Mac OS X's software RAID &amp; HFS+ and was
</I>&gt;<i> impressed by the performance.)
</I>&gt;<i>
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Since snapshots aren't fully baked in OS X yet, I think the easiest thing
</I>&gt;<i> &gt; would be option a.  (Feedback welcome! I haven't played with snapshots
</I>&gt;<i> yet)
</I>&gt;<i> &gt; but I can't figure how to do a mirror of a stripe.
</I>&gt;<i>
</I>&gt;<i> I think you mean a simple volume, not a stripped volume.  Most vdevs
</I>&gt;<i> are (dynamically) stripped (raidz is stripped, more than one mirror
</I>&gt;<i> vdev is stripped, ...).
</I>&gt;<i>
</I>&gt;<i> I think the cake will be fully baked Real Soon Now.  It seems like the
</I>&gt;<i> ZFS team has to provide a significant update for Snow Leopard some
</I>&gt;<i> time soon.  Don't invest too much in to your alternative solution
</I>&gt;<i> because ZFS will fully support snapshots before you know it (Feb?).
</I>&gt;<i>
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; I'm also considering buying another small SATA drive for OS X so I would
</I>&gt;<i> &gt; have 4x 320GB for a raidz pool.
</I>&gt;<i>
</I>&gt;<i> Best idea yet.  Consider creating a mirror out of them.  You'll get
</I>&gt;<i> better IOPS and can easily add disk to the pool (unlike raidz).
</I>&gt;<i>
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Basically my question is: what is a good, simple backup or replication
</I>&gt;<i> plan
</I>&gt;<i> &gt; for this scenario?
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Thoughts?
</I>&gt;<i> &gt; Aaron
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; _______________________________________________
</I>&gt;<i> &gt; zfs-discuss mailing list
</I>&gt;<i> &gt; <A HREF="http://lists.macosforge.org/mailman/listinfo.cgi/zfs-discuss">zfs-discuss at lists.macosforge.org</A>
</I>&gt;<i> &gt; <A HREF="http://lists.macosforge.org/mailman/listinfo.cgi/zfs-discuss">http://lists.macosforge.org/mailman/listinfo.cgi/zfs-discuss</A>
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i>
</I>-------------- next part --------------
An HTML attachment was scrubbed...
URL: &lt;<A HREF="http://lists.macosforge.org/pipermail/zfs-discuss/attachments/20081202/8aa20121/attachment.html">http://lists.macosforge.org/pipermail/zfs-discuss/attachments/20081202/8aa20121/attachment.html</A>&gt;
</PRE>


<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="001128.html">[zfs-discuss] Possible Mirror a stripe (or raidz) pool? Or	Replicate to separate pool?
</A></li>
	<LI>Next message: <A HREF="001133.html">[zfs-discuss] zfs and kernel memory?
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1132">[ date ]</a>
              <a href="thread.html#1132">[ thread ]</a>
              <a href="subject.html#1132">[ subject ]</a>
              <a href="author.html#1132">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://lists.macosforge.org/mailman/listinfo.cgi/zfs-discuss">More information about the zfs-discuss
mailing list</a><br>
</body></html>
