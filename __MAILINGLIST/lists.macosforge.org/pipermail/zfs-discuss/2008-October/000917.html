<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [zfs-discuss] read errors
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:zfs-discuss%40lists.macosforge.org?Subject=%5Bzfs-discuss%5D%20read%20errors&In-Reply-To=CF18DCA9-C82A-400B-A013-FFDCF0A5FD09%40universe42.com">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000915.html">
   <LINK REL="Next"  HREF="000916.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[zfs-discuss] read errors</H1>
    <B>Mr. Zorg</B> 
    <A HREF="mailto:zfs-discuss%40lists.macosforge.org?Subject=%5Bzfs-discuss%5D%20read%20errors&In-Reply-To=CF18DCA9-C82A-400B-A013-FFDCF0A5FD09%40universe42.com"
       TITLE="[zfs-discuss] read errors">zorg at sogeeky.net
       </A><BR>
    <I>Wed Oct  1 10:30:20 PDT 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="000915.html">[zfs-discuss] read errors
</A></li>
        <LI>Next message: <A HREF="000916.html">[zfs-discuss] late mount
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#917">[ date ]</a>
              <a href="thread.html#917">[ thread ]</a>
              <a href="subject.html#917">[ subject ]</a>
              <a href="author.html#917">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Your data is intact. The fact that it says applications are unaffected  
tells you that. It is able to work around the bad data and reconstruct  
from the parity info inherent on raidz. But it is telling you that the  
drive with the errors on it has some bad sectors. Most modern drives  
keep spare sectors in reserve and automatically use them when  
necessary, so this means you've probably exhausted those reserves.  
Pick up a new drive and use the zfs commands to replace the bad drive  
with the new one. Then pull the bad drive. The hard part is figuring  
out which drive number is which physical drive. I usually just shut  
down all apps and turn them off one by one until I see the one I want  
disappear. :)

I had something similar when the powersupply of an external drive was  
going bad causing the disk to periodically spin down. The drive itself  
was fine. But I am guessing that's not your problem since ther errors  
seem to happen in the same spot.

On Oct 1, 2008, at 10:13 AM, Brett Koonce &lt;<A HREF="http://lists.macosforge.org/mailman/listinfo.cgi/zfs-discuss">koonce at universe42.com</A>&gt; wrote:

&gt;<i> I built a little raidz array with 4 500GB hard drives in a Sans
</I>&gt;<i> Digital TRU-4 usb box.  I copied over some data (~700GB), ran a zfs
</I>&gt;<i> scrub and got this:
</I>&gt;<i>
</I>&gt;<i> $ zpool status
</I>&gt;<i>   pool: clover
</I>&gt;<i>  state: ONLINE
</I>&gt;<i> status: One or more devices has experienced an unrecoverable error.   
</I>&gt;<i> An
</I>&gt;<i>    attempt was made to correct the error.  Applications are  
</I>&gt;<i> unaffected.
</I>&gt;<i> action: Determine if the device needs to be replaced, and clear the
</I>&gt;<i> errors
</I>&gt;<i>    using 'zpool clear' or replace the device with 'zpool replace'.
</I>&gt;<i>    see: <A HREF="http://www.sun.com/msg/ZFS-8000-9P">http://www.sun.com/msg/ZFS-8000-9P</A>
</I>&gt;<i>  scrub: scrub in progress, 28.97% done, 12h15m to go
</I>&gt;<i> config:
</I>&gt;<i>
</I>&gt;<i>    NAME         STATE     READ WRITE CKSUM
</I>&gt;<i>    clover       ONLINE       0     0     0
</I>&gt;<i>      raidz1     ONLINE       0     0     0
</I>&gt;<i>        disk1s2  ONLINE       0     0     0
</I>&gt;<i>        disk2s2  ONLINE       0     0     0
</I>&gt;<i>        disk3s2  ONLINE       0     0     0
</I>&gt;<i>        disk4s2  ONLINE       9     0     0
</I>&gt;<i>
</I>&gt;<i> I decided to clear the errors and went along my merry way.  So a
</I>&gt;<i> couple days ago I decided to scrub things again, and got the exact
</I>&gt;<i> same results (9 read errors on disk4 near the 30% mark).
</I>&gt;<i>
</I>&gt;<i> So, my questions:
</I>&gt;<i>
</I>&gt;<i> I was under the impression that zfs would attempt to repair the
</I>&gt;<i> errors.  Or rather, is the fact that I got the same numbers twice a
</I>&gt;<i> weird coincidence?  (i.e. are they the same 9 errors?)
</I>&gt;<i>
</I>&gt;<i> My understanding (correct me if I'm wrong) is that zfs will only
</I>&gt;<i> attempt to fix things on a COW operation.  In that case, if I was to
</I>&gt;<i> find the file in question, duplicate/replace it from my other backups,
</I>&gt;<i> and delete the original, would this theoretically get around the bad
</I>&gt;<i> sectors?  Is there a way to get that information out of zfs?  The
</I>&gt;<i> system.log only mentions the errors happened.
</I>&gt;<i>
</I>&gt;<i> I guess I should just pony up the fifty bucks for a new drive.  But
</I>&gt;<i> I'd like to know how this works.  Thanks in advance,
</I>&gt;<i> -Brett
</I>&gt;<i> _______________________________________________
</I>&gt;<i> zfs-discuss mailing list
</I>&gt;<i> <A HREF="http://lists.macosforge.org/mailman/listinfo.cgi/zfs-discuss">zfs-discuss at lists.macosforge.org</A>
</I>&gt;<i> <A HREF="http://lists.macosforge.org/mailman/listinfo.cgi/zfs-discuss">http://lists.macosforge.org/mailman/listinfo.cgi/zfs-discuss</A>
</I></PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000915.html">[zfs-discuss] read errors
</A></li>
	<LI>Next message: <A HREF="000916.html">[zfs-discuss] late mount
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#917">[ date ]</a>
              <a href="thread.html#917">[ thread ]</a>
              <a href="subject.html#917">[ subject ]</a>
              <a href="author.html#917">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://lists.macosforge.org/mailman/listinfo.cgi/zfs-discuss">More information about the zfs-discuss
mailing list</a><br>
</body></html>
