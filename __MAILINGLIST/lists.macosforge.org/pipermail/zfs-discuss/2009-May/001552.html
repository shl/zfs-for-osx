<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [zfs-discuss] There is something very wrong with the MacOS ZFS	documentation
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:zfs-discuss%40lists.macosforge.org?Subject=Re%3A%20%5Bzfs-discuss%5D%20There%20is%20something%20very%20wrong%20with%20the%20MacOS%20ZFS%0A%09documentation&In-Reply-To=%3C72feba2a0905050854t367f391uae7e3605817420ff%40mail.gmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="001551.html">
   <LINK REL="Next"  HREF="001553.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[zfs-discuss] There is something very wrong with the MacOS ZFS	documentation</H1>
    <B>Adrian Thornton</B> 
    <A HREF="mailto:zfs-discuss%40lists.macosforge.org?Subject=Re%3A%20%5Bzfs-discuss%5D%20There%20is%20something%20very%20wrong%20with%20the%20MacOS%20ZFS%0A%09documentation&In-Reply-To=%3C72feba2a0905050854t367f391uae7e3605817420ff%40mail.gmail.com%3E"
       TITLE="[zfs-discuss] There is something very wrong with the MacOS ZFS	documentation">canadrian at electricteaparty.net
       </A><BR>
    <I>Tue May  5 08:54:37 PDT 2009</I>
    <P><UL>
        <LI>Previous message: <A HREF="001551.html">[zfs-discuss] There is something very wrong with the MacOS ZFS	documentation
</A></li>
        <LI>Next message: <A HREF="001553.html">[zfs-discuss] There is something very wrong with the MacOS ZFS	documentation
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1552">[ date ]</a>
              <a href="thread.html#1552">[ thread ]</a>
              <a href="subject.html#1552">[ subject ]</a>
              <a href="author.html#1552">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Alex Bowden,

zpool status isn't going to give you anything if your pool is unmounted.
It'll say there are no pools. You need to do &quot;zpool import&quot; and it will list
the pools available for import.

At any rate, I made the same mistake when I first set up my OS X pool. I
used the whole disk because that's what the Sun instructions said worked
best. It never re-mounted when I rebooted - i.e. &quot;zpool status&quot; would turn
up nothing, and &quot;zpool import&quot; would list it as available for import, so I'd
have to type &quot;zpool import Archives&quot; (Archives being the name of my RAIDZ).
I also experienced a catastrophic loss of everything while iteratively
replacing all the disks with larger ones, and hat other weirdness between.
When I started from scratch with the bigger disks, I had learned my lesson -
follow the OS X ZFS instructions and use the slices instead of the whole
disks. It's been rock-solid since then.

I understand how ticked you probably are at losing everything. I know I was.
But you have to remember that ZFS on OS X isn't intended for production use
at this point anyway. You kinda have to do what I did and admit, &quot;well, I
guess I should have known something like this would happen,&quot; and move on
with it. No need for raised tempers.

Meanwhile, try &quot;zpool import&quot; rather than &quot;zpool status&quot; and see if it lists
your pool.

- Adrian

On Tue, May 5, 2009 at 09:23, Alex Bowden &lt;<A HREF="http://lists.macosforge.org/mailman/listinfo.cgi/zfs-discuss">alex at designlifecycle.com</A>&gt; wrote:

&gt;<i>
</I>&gt;<i> Alex Blewitt
</I>&gt;<i>
</I>&gt;<i> Thank you for your response.
</I>&gt;<i>
</I>&gt;<i> Firstly your final comment
</I>&gt;<i>
</I>&gt;<i> &quot;follow the instructions on the getting started page, and not what you
</I>&gt;<i> think they say.&quot;
</I>&gt;<i>
</I>&gt;<i> In turn may I I suggest that you try reading my email on something larger
</I>&gt;<i> that your (new) iphone and you may find out what I actually said.  And not
</I>&gt;<i> what you think I said.
</I>&gt;<i>
</I>&gt;<i> Let me repeat.
</I>&gt;<i>
</I>&gt;<i> The instructions, where it gives you a recipe to type, work fine.
</I>&gt;<i>
</I>&gt;<i> But the dialogue text clearly recommends that for best results, one should
</I>&gt;<i> use the whole disk.  That is in the first paragraph.
</I>&gt;<i>
</I>&gt;<i> Using the whole disk means /dev/disk2 NOT /dev/disk2s2 with a 100% slice
</I>&gt;<i>
</I>&gt;<i> When I use the whole disk, then after a reboot the zpool is gone.  Not
</I>&gt;<i> unmounted .  Gone.
</I>&gt;<i>
</I>&gt;<i> i.e.  &quot;zpool status&quot; doesn't know of its existence.
</I>&gt;<i>
</I>&gt;<i> It is repeatable.
</I>&gt;<i>
</I>&gt;<i> It is broken.
</I>&gt;<i>
</I>&gt;<i> If it wasn't nailed to its perch it would be pushing up daisies.
</I>&gt;<i>
</I>&gt;<i> It is a dead parrot.
</I>&gt;<i>
</I>&gt;<i> If there hasn't been any public development since 119 then I suggest that
</I>&gt;<i> it has probably been broken since 119,  or that something else that has
</I>&gt;<i> changed has triggered the effect.
</I>&gt;<i>
</I>&gt;<i> I have made no comments about 10.5 or 10.6 or backporting,  but the
</I>&gt;<i> problems occured under 10.5.6 with the 119 zfs.kext.
</I>&gt;<i>
</I>&gt;<i> You probably wouldn't notice that it was broken because you would do what
</I>&gt;<i> it expects.  Not what the getting started notes actually recommend.
</I>&gt;<i>
</I>&gt;<i> Perhaps you are too blinded by expecting people to have automounter
</I>&gt;<i> problems to not see complaints about zpools vanishing.
</I>&gt;<i>
</I>&gt;<i> Because there was nothing in Teng Yao's email to lead you to give the &quot;read
</I>&gt;<i> the instructions&quot; answer there either.
</I>&gt;<i>
</I>&gt;<i> If its broken, and everybody knows that its broken, then why not just say
</I>&gt;<i> so at the top of the instructions.
</I>&gt;<i>
</I>&gt;<i> Alex
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> On 5 May 2009, at 12:36, Alex Blewitt wrote:
</I>&gt;<i>
</I>&gt;<i> I suspect your analysis - that you were ranting - isn't far off the mark.
</I>&gt;<i>
</I>&gt;<i> There has been no public development of ZFS since 119 and at this point,
</I>&gt;<i> there won't be any for 10.5.
</I>&gt;<i>
</I>&gt;<i> 10.6 is round the corner and will have tighter integration with the OS,
</I>&gt;<i> especially finder/spotlight. Those won't be backported to 10.5.
</I>&gt;<i>
</I>&gt;<i> The reason for the partition on a disk (rather than the &quot;well known&quot; whole
</I>&gt;<i> disk thing) is to allow the kernel to mount it automatically. It can still
</I>&gt;<i> be mounted manually if you want. The instructions do say to follow this
</I>&gt;<i> advice - and FWIW if you give the OSX a &quot;full&quot; disk (albeit in a partition)
</I>&gt;<i> then I believe the whole disk optimisations kick in.
</I>&gt;<i>
</I>&gt;<i> Diskutil (GUI) will have support in 10.6 but not 10.5.
</I>&gt;<i>
</I>&gt;<i> There are two recurring issues on this list;
</I>&gt;<i>
</I>&gt;<i> 1) I used a USB disk with a non-replicated FS and when I pulled it the
</I>&gt;<i> machine froze
</I>&gt;<i> 2) my pool doesn't mount on boot
</I>&gt;<i>
</I>&gt;<i> For 1, later versions of ZFS in Solaris have an option to not panic on ZFS
</I>&gt;<i> failure. However, it is not and will never be in 10.5. Anyway, if you're not
</I>&gt;<i> replicating data you're at a risk of data loss.
</I>&gt;<i>
</I>&gt;<i> For 2, follow the instructions on the getting started page, and not what
</I>&gt;<i> you think they say.
</I>&gt;<i>
</I>&gt;<i> Alex
</I>&gt;<i>
</I>&gt;<i> Sent from my (new) iPhone
</I>&gt;<i>
</I>&gt;<i> On 5 May 2009, at 11:37, Alex Bowden &lt;<A HREF="http://lists.macosforge.org/mailman/listinfo.cgi/zfs-discuss">alex at designlifecycle.com</A>&gt; wrote:
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> Hi
</I>&gt;<i>
</I>&gt;<i> There is something very wrong with the MacOS ZFS documentation (and also to
</I>&gt;<i> an extent software).
</I>&gt;<i>
</I>&gt;<i> I have been using ZFS under Solaris for a couple of years and know it to a
</I>&gt;<i> superb facility.
</I>&gt;<i>
</I>&gt;<i> Otherwise, my initial experience on the Mac would have caused me to bin it.
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> Lets start with the Documentation.  The main ZFS documentation set
</I>&gt;<i> documents ZFS so what I am looking for from the Mac side is simply to
</I>&gt;<i> document the differences and issues in using the software under MacOS.   If
</I>&gt;<i> fails dismally.
</I>&gt;<i>
</I>&gt;<i> It fails so badly that I, and others, are loosing zpools  (Oh, God, I lost
</I>&gt;<i> every thing after a reboot !!!).
</I>&gt;<i>
</I>&gt;<i> Lets start with the &quot;getting started&quot;.
</I>&gt;<i>
</I>&gt;<i> Paragraph one.
</I>&gt;<i>
</I>&gt;<i> &quot;*In all cases, the disks need to use the GUID Partition Table (GPT)* and
</I>&gt;<i> ZFS typically works best when it owns the entire disk due in part to how
</I>&gt;<i> conservative it is with the write cache.&quot;
</I>&gt;<i>
</I>&gt;<i> Now it is well documented that ZFS works best when it owns the entire disk,
</I>&gt;<i> partly I believe because it can then control the caching strategy for the
</I>&gt;<i> disk.
</I>&gt;<i>
</I>&gt;<i> The trouble is that under MacOS it seems to be essential that you DON'T
</I>&gt;<i> give ZFS the whole disk.  If you do it will work fine until you reboot and
</I>&gt;<i> then it'll trash your zpool.
</I>&gt;<i>
</I>&gt;<i> The examples work rather better than the stated advice.
</I>&gt;<i>
</I>&gt;<i> # diskutil partitiondisk /dev/disk2 GPTFormat ZFS %noformat% 100%
</I>&gt;<i> # zpool create puddle /dev/disk2s2
</I>&gt;<i>
</I>&gt;<i> OK,  that works fine BUT
</I>&gt;<i>
</I>&gt;<i> A) It does NOT give ZFS the whole disk.  It gives a single partition i.e.
</I>&gt;<i>  slice 2 of the disk.   This is most of the disk but not the whole of it.
</I>&gt;<i>
</I>&gt;<i> B) It silently introduces a new concept which is a partition of type ZFS
</I>&gt;<i> which isn't even offered as an option in diskutil.app but which seems to be
</I>&gt;<i> essential for a stable zpool.
</I>&gt;<i>
</I>&gt;<i> C) Why introduce a new user to a single disk zpool.   Thats about as
</I>&gt;<i> useful as a banking regulator.
</I>&gt;<i>
</I>&gt;<i> And I am left trying to guess whether the Mac ZFS handles a 100% ZFS slice
</I>&gt;<i> in a GPT partition as being the whole disk for caching purposes, or whether
</I>&gt;<i> I end up with a degraded ZFS because it doesn't have the whole disk.
</I>&gt;<i>
</I>&gt;<i> What else don't you tell us.  Lets look ahead a little.
</I>&gt;<i>
</I>&gt;<i> Well how about the zfs command.  Anyone used to ZFS will know that the ZFS
</I>&gt;<i> filesystem created by the zpool command is not generally used as a working
</I>&gt;<i> filesystems but as an administrative bucket for the zpool.
</I>&gt;<i>
</I>&gt;<i> After creating the zpool it is then normal to add your ZFS filesystems
</I>&gt;<i> using the zpool command.  This is completely unmentioned, which helps gloss
</I>&gt;<i> over the problems mounting other ZFS file systems once created.
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> Then there is the fact that about one or two ZFS partition creation
</I>&gt;<i> commands,  the disk system gets manically busy for an indeterminate period
</I>&gt;<i> of time, &quot;diskutil list&quot; returns unstable results and the machine is likely
</I>&gt;<i> to freeze.
</I>&gt;<i>
</I>&gt;<i> It seems to be best to build one ZFS partition at time.  Wait for all disk
</I>&gt;<i> activity to stop, and then reboot, before building the next one.
</I>&gt;<i>
</I>&gt;<i> So now lets look at the software.  The good news is that it is possible to
</I>&gt;<i> build a working ZFS filesystem if you a) do that is expected rather than
</I>&gt;<i> what the &quot;getting started&quot; says works best and b) build the ZFS partitions
</I>&gt;<i> very gently.
</I>&gt;<i>
</I>&gt;<i> But if instead you follow the worded instructions, ZFS manual, general ZFS
</I>&gt;<i> documentation etc, and give it the whole disk
</I>&gt;<i>
</I>&gt;<i> zpool create lake raidz /dev/disk2 /dev/disk3 /dev/disk4 /dev/disk5
</I>&gt;<i>
</I>&gt;<i> You now have a whole pile of trouble.  loss of the whole zpool when you
</I>&gt;<i> reboot is just the beginning.
</I>&gt;<i>
</I>&gt;<i> Because while you go off and start again trying to set up your system.  zfs
</I>&gt;<i> gets clever and starts trying to recover the zpool.  I never succeeds, but
</I>&gt;<i> it wont easily stop either.
</I>&gt;<i>
</I>&gt;<i> There is a very pretty situation in diskutil.app where all the partitions
</I>&gt;<i> that were part of &quot;lake&quot; keep appearing and vanishing again, out of phase
</I>&gt;<i> with each other, at about one second intervals.
</I>&gt;<i>
</I>&gt;<i> Reformat the disks as MBR all free space and then back as GPT (usually
</I>&gt;<i> clears anything), but no,  zfs still finds them again.
</I>&gt;<i>
</I>&gt;<i> Documetation is very clear that you must delete the zpool using the zpool
</I>&gt;<i> destroy command.
</I>&gt;<i>
</I>&gt;<i> But you can't do that when ZFS think that the pool doesn't exist.
</I>&gt;<i>
</I>&gt;<i> In the end the only way I managed to move forward was to zero the disks
</I>&gt;<i> with Ranish from a live linux cd.
</I>&gt;<i>
</I>&gt;<i> And this is all the consequence of following the standard advise in the
</I>&gt;<i> MacOS ZFS &quot;getting started&quot;, e.g. that &quot;ZFS typically works best when it
</I>&gt;<i> owns the entire disk&quot;.
</I>&gt;<i>
</I>&gt;<i> I note that on this list only last week Teng Yao had the same problem (Oh,
</I>&gt;<i> God, I lost every thing after a reboot !!!)
</I>&gt;<i>
</I>&gt;<i> and Alex Blewitt helpfully replied that
</I>&gt;<i>
</I>&gt;<i> &quot;The documentation suggested /dev/disk0s2 would have been better,
</I>&gt;<i>
</I>&gt;<i> rather than /dev/disk0, as otherwise ti doesn't mount on boot. That
</I>&gt;<i> sounds like what's happened here.&quot;
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> Er - Well actually it doesn't.  That may be what it does in the example,  but it clearly advises that you use the whole disk.
</I>&gt;<i>
</I>&gt;<i> 	
</I>&gt;<i> Sorry if I am ranting a little but this is a serious mess.
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> 	 &lt;<A HREF="http://lists.macosforge.org/mailman/listinfo.cgi/zfs-discuss">Alex at designlifecycle.com</A>&gt;<A HREF="http://lists.macosforge.org/mailman/listinfo.cgi/zfs-discuss">Alex at designlifecycle.com</A>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> _______________________________________________
</I>&gt;<i> zfs-discuss mailing list
</I>&gt;<i> <A HREF="http://lists.macosforge.org/mailman/listinfo.cgi/zfs-discuss">zfs-discuss at lists.macosforge.org</A>
</I>&gt;<i> <A HREF="http://lists.macosforge.org/mailman/listinfo.cgi/zfs-discuss">http://lists.macosforge.org/mailman/listinfo.cgi/zfs-discuss</A>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> _______________________________________________
</I>&gt;<i> zfs-discuss mailing list
</I>&gt;<i> <A HREF="http://lists.macosforge.org/mailman/listinfo.cgi/zfs-discuss">zfs-discuss at lists.macosforge.org</A>
</I>&gt;<i> <A HREF="http://lists.macosforge.org/mailman/listinfo.cgi/zfs-discuss">http://lists.macosforge.org/mailman/listinfo.cgi/zfs-discuss</A>
</I>&gt;<i>
</I>&gt;<i>
</I>-------------- next part --------------
An HTML attachment was scrubbed...
URL: &lt;<A HREF="http://lists.macosforge.org/pipermail/zfs-discuss/attachments/20090505/312fa8c2/attachment-0001.html">http://lists.macosforge.org/pipermail/zfs-discuss/attachments/20090505/312fa8c2/attachment-0001.html</A>&gt;
</PRE>


<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="001551.html">[zfs-discuss] There is something very wrong with the MacOS ZFS	documentation
</A></li>
	<LI>Next message: <A HREF="001553.html">[zfs-discuss] There is something very wrong with the MacOS ZFS	documentation
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1552">[ date ]</a>
              <a href="thread.html#1552">[ thread ]</a>
              <a href="subject.html#1552">[ subject ]</a>
              <a href="author.html#1552">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://lists.macosforge.org/mailman/listinfo.cgi/zfs-discuss">More information about the zfs-discuss
mailing list</a><br>
</body></html>
